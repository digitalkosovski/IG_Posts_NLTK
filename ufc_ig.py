# -*- coding: utf-8 -*-
"""UFC_IG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ULWe3b07pNtjWsa35kxKzNTmavHAeIep
"""

pip install nltk

pip install spacy

pip install stopwordsiso

#import nlp tools
import nltk
import stopwordsiso as stops
from string import punctuation
import spacy

#import tools for visualization and analysis
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
from wordcloud import WordCloud

# Load your data from IG
df = pd.read_json("/content/sample_data/dataset_instagram-scraper_2025-02-27_13-04-18-736.json")

#Ordering by most comments
df = df.sort_values(by='commentsCount', ascending=False)
#Selecting the 500 posts with most comments
df = df.head(500)



# Merging values in 'caption' column for the same IG user in a dictionary:
grouped_text = df.groupby('inputUrl')['caption'].apply(lambda x: ' '.join(x)).to_dict()

print(grouped_text)

#Establishing stopwords, punctuation marks, and common terms
stops_en = stops.stopwords('en')
stops_pt = stops.stopwords('pt')
punctuation_marks = {'.', ',', '!', '?', ';', ':', '-', '_', '(', ')', '[', ']', '{', '}',
    '"', "'", '<', '>', '/', '\\', '@', '#', '$', '%', '^', '&', '*',
    '+', '=', '|', '~', '`', '…', '“', '”', '‘', '’', '•', '¶', '©', '®'}
stops_ufc = {'stylebender', 'israeladesanya', 'mma', 'israel', 'adesanya', 'thenotoriousmma', 'conor', 'mcgregor', 'conormcgregor', 'charlesdobronx', 'oliveira', 'charlesdobronxs','charles', 'dobronx', 'francisngannou', 'francis', 'ngannou', 'jonny', 'bones', 'jonnybones', 'ufc'}

from google.colab import files

# Generate and plot word clouds for each user
for user, text in grouped_text.items():
    text = text.lower()
    normalized = ''.join([char for char in text if char not in punctuation and char.isnumeric()==False])
    normalized_no_stops = [word for word in normalized.split() if word not in stops_en and word not in stops_pt and word not in fighters]
    normalized_no_stops_text = ''.join(normalized_no_stops)
    with open(f"{user}.txt", "w", encoding="utf-8") as file:
        file.write(text)
        files.download(f"{user}.txt")

    wordcloud = WordCloud(width=400, height=400, background_color='white', max_words=20).generate(normalized_no_stops_text)



   # plt.figure(figsize=(5, 4))
    #plt.imshow(wordcloud, interpolation='bilinear')
    #plt.axis('off')
    #plt.title(f'Word Cloud for user: {user}')
    #plt.show()

import os
# Generate txt files for each user
for user, text in grouped_text.items():
    # Extract the username from the URL
    username = user.rstrip("/")
    username = username.split('/')[-1]
    #normalize text
    text = text.lower()
    normalized_no_stops = [word for word in text.split() if word not in stops_en and word not in stops_pt and word not in stops_ufc]
    normalized_no_stops_text = ''.join(normalized_no_stops)
    normalized = ''.join([char for char in text if char not in punctuation and char.isnumeric()==False])
    normalized = [word for word in normalized.split() if word not in stops_en and word not in stops_pt and word not in stops_ufc]
    normalized = ' '.join(normalized)

    # Create a filename using the extracted username
    filename = f"{username}.txt"

    with open(filename, "w", encoding="utf-8") as file:
        file.write(normalized)
        files.download(filename)





